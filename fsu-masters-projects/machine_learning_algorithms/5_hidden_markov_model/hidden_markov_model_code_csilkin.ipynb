{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971237bf-33de-47ac-a774-54d5f42cbbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCharles Silkin\\nHidden Markov Model Project Code\\nFSU Interdisciplinary Data Science Master's Program - Applied Machine Learning Course\\n7 March 2023\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Charles Silkin\n",
    "Hidden Markov Model Project Code\n",
    "FSU Interdisciplinary Data Science Master's Program - Applied Machine Learning Course\n",
    "7 March 2023\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b2332e-6378-47cd-ba6c-d9f116a5f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc17b89f-cef4-48d9-b3c6-da753a86f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 5. 5. 1. 3. 6. 3. 2. 3. 6. 6. 1. 3. 3. 2. 3. 4. 3. 1. 2. 2. 4. 2.\n",
      " 5. 6. 3. 2. 1. 5. 5. 2. 2. 5. 3. 4. 1. 6. 6. 1. 5. 5. 2. 6. 2. 1. 1. 3.\n",
      " 6. 1. 4. 3. 1. 2. 2. 6. 3. 3. 1. 2. 1. 6. 4. 3. 2. 3. 1. 1. 5. 1. 2. 4.\n",
      " 1. 3. 2. 6. 1. 6. 6. 1. 6. 6. 5. 4. 6. 5. 2. 3. 3. 1. 5. 6. 2. 6. 3. 6.\n",
      " 6. 3. 3. 3. 6. 6. 6. 6. 5. 1. 2. 6. 6. 6. 2. 6. 6. 6. 3. 5. 2. 6. 3. 6.\n",
      " 2. 6. 6. 1. 3. 1. 1. 4. 5. 6. 2. 3. 1. 3. 6. 2. 6. 6. 3. 5. 4. 5. 6. 3.\n",
      " 3. 2. 6. 2. 6. 3. 3. 2. 5. 3. 6. 5. 3. 5. 2. 1. 3. 6. 2. 5. 5. 1. 6. 6.\n",
      " 6. 6. 1. 5. 2. 4. 6. 1. 2. 4. 3. 1. 3. 3. 1. 2. 2. 6. 6. 6. 5. 4. 3. 3.\n",
      " 3. 6. 3. 2. 2. 3. 1. 4. 5. 5. 2. 5. 4. 3. 1. 6. 1. 2. 6. 4. 2. 6. 6. 3.\n",
      " 1. 2. 6. 5. 5. 6. 6. 6. 6. 6. 6. 6. 3. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6.\n",
      " 6. 4. 4. 6. 6. 2. 2. 6. 6. 3. 6. 6. 2. 5. 6. 3. 6. 4. 4. 6. 6. 6. 6. 2.\n",
      " 4. 6. 2. 6. 6. 6. 6. 6. 6. 4. 3.]\n",
      "[6. 4. 2. ... 1. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Load hmm_pb1.csv\n",
    "x = np.loadtxt(\"hmm_pb1.csv\", delimiter = \",\")\n",
    "print(x)\n",
    "# Load hmm_pb2.csv\n",
    "x2 = np.loadtxt(\"hmm_pb2.csv\", delimiter = \",\")\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3f80ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "pi = [0.5,0.5]\n",
    "a = np.array(((0.95,0.05),(0.05,0.95)))\n",
    "b = np.array(((1/6,1/6,1/6,1/6,1/6,1/6),(0.1,0.1,0.1,0.1,0.1,0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d3ddcda-bd41-4a21-9f3c-21339bc8577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,"
     ]
    }
   ],
   "source": [
    "# Viterbi algorithm:\n",
    "def Viterbi(x,a,b,pi):\n",
    "    ## Initialize i and k\n",
    "    i = x.shape[0]\n",
    "    k = a.shape[0]\n",
    "    \n",
    "    ## Create C matrix\n",
    "    C = np.zeros((i, k))\n",
    "    \n",
    "    ## Initialize first row of C\n",
    "    b_0 = b[:, int(x[0])-1]\n",
    "    \n",
    "    C[0,:] = np.log(pi * b_0)\n",
    "    \n",
    "    ## Create matrix of most probable hidden states\n",
    "    prev = np.zeros((i-1, k))\n",
    "    \n",
    "    ## Iterate over time range\n",
    "    for t in range(1, i):\n",
    "        for j in range(k):\n",
    "            ### Obtain probability values\n",
    "            b_xt = b[j, int(x[t])-1]\n",
    "            probability = C[t-1] + np.log(a[:,j]) + np.log(b_xt)\n",
    "\n",
    "            # Update matrix of most probable hidden states\n",
    "            prev[t-1, j] = np.argmax(probability)\n",
    "\n",
    "            # Update row t of C matrix with probability of the most probable state\n",
    "            C[t,j] = np.max(probability)\n",
    "\n",
    "    ## Array of sequence\n",
    "    S = np.zeros(i)\n",
    "\n",
    "    ## Find the most probable last hidden state\n",
    "    last_state = np.argmax(C[i-1, :])\n",
    "\n",
    "    S[0] = last_state\n",
    "    \n",
    "    ## Trace back through most probable hidden states to get full y*\n",
    "    backtrack_index = 1\n",
    "    for m in range(i-2, -1, -1):\n",
    "        S[backtrack_index] = prev[m, int(last_state)]\n",
    "        last_state = prev[m, int(last_state)]\n",
    "        backtrack_index += 1\n",
    "\n",
    "    ### Flip sequence array since we were backtracking\n",
    "    S = np.flip(S, axis=0)\n",
    "    \n",
    "    ### Replace state values with \"1\" for fair, \"2\" for loaded\n",
    "    y = []\n",
    "    for s in S:\n",
    "        if s == 0:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(2)\n",
    "    \n",
    "    ### Return final sequence\n",
    "    return y\n",
    "\n",
    "# PART 1.A RESULT:\n",
    "for yi in Viterbi(x,a,b,pi):\n",
    "    print(yi, end = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deeafeb2-55b5-4bc5-95b6-053be7ad28a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8402448607351627 0.15975513926483742 5.259579532788797\n",
      "0.2230859777601995 0.7769140222398006 0.28714371394283095\n"
     ]
    }
   ],
   "source": [
    "# Forward algorithm:\n",
    "def forward_algorithm(x,a,b,pi):\n",
    "    \n",
    "    ## Initialize i and k\n",
    "    i = x.shape[0]\n",
    "    k = a.shape[0]\n",
    "    \n",
    "    ## Create matrix of alphas\n",
    "    alpha_mat = np.zeros((i, k))\n",
    "    \n",
    "    ## Initialize first row of alpha matrix\n",
    "    b_0 = b[:, int(x[0])-1]\n",
    "    alpha_mat[0,:] = (pi * b_0)\n",
    "\n",
    "    ## Normalize alphas so that probabilities of each row sum to 1\n",
    "    alpha_mat[0,:] = alpha_mat[0,:] / np.sum(alpha_mat[0,:], axis = 0)\n",
    "    \n",
    "    ## Obtain alpha values at time t\n",
    "    for t in range(1, i):\n",
    "        for j in range(k):\n",
    "            b_xt = b[j, int(x[t])-1]\n",
    "            alpha_mat[t,j] = b_xt * np.dot(alpha_mat[t-1], a[:,j])\n",
    "        ### Normalize alphas so that probabilities of each row sum to 1\n",
    "        alpha_mat[t,:] = alpha_mat[t,:] / np.sum(alpha_mat[t,:], axis = 0)\n",
    "    \n",
    "    ## Return alpha matrix\n",
    "    return alpha_mat\n",
    "\n",
    "# Backwards algorithm:\n",
    "def backward_algorithm(x,a,b):\n",
    "    \n",
    "    ## Initialize i and k\n",
    "    i = x.shape[0]\n",
    "    k = a.shape[0]\n",
    "    \n",
    "    ## Create matrix of betas\n",
    "    beta_mat = np.zeros((i, k))\n",
    "\n",
    "    ## Initialize last row of betas as ones\n",
    "    beta_mat[i-1] = np.ones((k))\n",
    "    \n",
    "    ## Normalize betas so that probabilities of each row sum to 1\n",
    "    beta_mat[i-1] = beta_mat[i-1] / np.sum(beta_mat[i-1], axis = 0)\n",
    "    \n",
    "    ## Obtain betas at time t+1\n",
    "    for t in range(i-2, -1, -1):\n",
    "        for j in range(k):\n",
    "            b_xt_plus1 = b[j, int(x[t+1])-1]\n",
    "            beta_mat[t,j] = np.dot((beta_mat[t+1] * b_xt_plus1), a[j,:])\n",
    "        \n",
    "        ### Normalize betas so that probabilities of each row sum to 1\n",
    "        beta_mat[t,:] = beta_mat[t,:] / np.sum(beta_mat[t,:], axis = 0)\n",
    "    \n",
    "    ## Return beta matrix\n",
    "    return beta_mat\n",
    "\n",
    "# PART 1.B RESULTS:\n",
    "alpha_133 = forward_algorithm(x,a,b,pi)[133]\n",
    "\n",
    "alpha_rat = alpha_133[0] / alpha_133[1]\n",
    "\n",
    "print(alpha_133[0], alpha_133[1], alpha_rat)\n",
    "\n",
    "beta_133 = backward_algorithm(x,a,b)[133]\n",
    "\n",
    "beta_rat = beta_133[0] / beta_133[1]\n",
    "\n",
    "print(beta_133[0], beta_133[1], beta_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ad81bb5-a051-4636-b0b0-e022691e3242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.00115187, 0.99884813]), array([[0.62461341, 0.37538659],\n",
      "       [0.01246032, 0.98753968]]), array([[0.07851282, 0.11030791, 0.06205056, 0.03949162, 0.62527238,\n",
      "        0.08436471],\n",
      "       [0.20077315, 0.20516004, 0.19296135, 0.20077316, 0.1068278 ,\n",
      "        0.0935045 ]]))\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters with custom values\n",
    "pi2 = [0.87,0.13]\n",
    "a2 = np.array(((0.87,0.13), (0.13,0.87)))\n",
    "b2 = np.array(((1/6,1/6,1/6,1/6,1/6,1/6), (0.3,0.27,0.05,0.16,0.11,0.11)))\n",
    "\n",
    "# Baum-Welch algorithm:\n",
    "def Baum_Welch(x,a,b,pi,n_iter=1000):\n",
    "    ## Initialize i and k\n",
    "    i = x.shape[0]\n",
    "    k = a.shape[0]\n",
    "    \n",
    "    ## Iterations\n",
    "    for n in range(n_iter):\n",
    "        \n",
    "        ### Initialize alphas and betas\n",
    "        alpha = forward_algorithm(x,a,b,pi)\n",
    "        beta = backward_algorithm(x,a,b)\n",
    "        \n",
    "        ### Create xi matrix\n",
    "        xi = np.zeros((k,k,i-1))\n",
    "        \n",
    "        ### Compute appropriate values of xi\n",
    "        for t in range(i-1):\n",
    "            b_xt_plus1 = b[:, int(x[t+1])-1]\n",
    "            denom_pt1 = np.dot(alpha[t,:], a) * b_xt_plus1\n",
    "            denom = np.dot(denom_pt1,beta[t+1,:])\n",
    "            \n",
    "            for j in range(k):\n",
    "                alpha_A = alpha[t,j] * a[j,:]\n",
    "\n",
    "                beta_B = b_xt_plus1 * beta[t+1,:]\n",
    "\n",
    "                num = alpha_A * beta_B\n",
    "\n",
    "                xi[j,:,t] = num/denom\n",
    "        \n",
    "        ## Create gamma matrix\n",
    "        gamma = np.sum(xi, axis = 1)\n",
    "        \n",
    "        ## Update pi as gamma values at time t=1\n",
    "        pi = gamma[:,1]/np.sum(gamma[:,1])\n",
    "        \n",
    "        ## Update a\n",
    "        a_num = np.sum(xi, 2) ### Normalization to ensure horizontal sums of 1\n",
    "        a_denom = np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "\n",
    "        a = a_num / a_denom\n",
    "        \n",
    "        ## Add element to end of gamma to match dimensions\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:,:,i-2], axis=0).reshape((-1, 1))))\n",
    "        \n",
    "        ## Update b\n",
    "        b_denom = np.sum(gamma, axis=1).reshape((-1, 1)) ### Normalization to ensure horizontal sums of 1\n",
    "        \n",
    "        for num in range(b.shape[1]):\n",
    "            b[:, num] = np.sum(gamma[:, x == num+1], axis=1)\n",
    "        \n",
    "        b = b/b_denom\n",
    "    \n",
    "    ## Return final parameters\n",
    "    return (pi, a, b)\n",
    "\n",
    "# PART 2 RESULTS:\n",
    "print(Baum_Welch(x2,a2,b2,pi2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
